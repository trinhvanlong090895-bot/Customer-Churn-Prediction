import streamlit as st
import pandas as pd
import numpy as np
import pickle

st.title("üìä AI Customer Churn Prediction")
st.write("D·ª± ƒëo√°n kh√°ch h√†ng c√≥ r·ªùi b·ªè hay kh√¥ng d·ª±a tr√™n m√¥ h√¨nh Machine Learning")

# Load model, scaler v√† feature_names
model = pickle.load(open("model.pkl", "rb"))
scaler = pickle.load(open("scaler.pkl", "rb"))
feature_names = pickle.load(open("feature_names.pkl", "rb"))  # ‚Üê Th√™m d√≤ng n√†y

uploaded_file = st.file_uploader("üì• T·∫£i file CSV Telco Customer Churn", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    st.subheader("üìÑ D·ªØ li·ªáu ƒë·∫ßu v√†o:")
    st.dataframe(df.head())

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
    df = df.dropna()

    df_processed = pd.get_dummies(df, drop_first=True)

    # ƒê·ªìng b·ªô v·ªõi c·ªôt c·ªßa model
    missing_cols = set(feature_names) - set(df_processed.columns)  # ‚Üê S·ª≠a d√≤ng n√†y
    for c in missing_cols:
        df_processed[c] = 0

    df_processed = df_processed[feature_names]  # ‚Üê S·ª≠a d√≤ng n√†y

    # Scale
    X_scaled = scaler.transform(df_processed)

    # Predict
    proba = model.predict_proba(X_scaled)[:, 1]

    df["Churn_Score"] = proba

    st.subheader("üîç K·∫øt qu·∫£ d·ª± ƒëo√°n:")
    st.dataframe(df.sort_values(by="Churn_Score", ascending=False))

    st.subheader("üî• Kh√°ch h√†ng c√≥ nguy c∆° cao (Churn > 0.7):")
    st.dataframe(df[df["Churn_Score"] > 0.7])

    st.bar_chart(df["Churn_Score"])
# --- B·∫ÆT ƒê·∫¶U PH·∫¶N CODE M·ªöI (D√°n ti·∫øp theo d√≤ng 49) ---

st.markdown("---")
st.title("üõ°Ô∏è Chi·∫øn l∆∞·ª£c Gi·ªØ ch√¢n Kh√°ch h√†ng (SoftBank Action Center)")

# 1. L·ªçc danh s√°ch kh√°ch h√†ng r·ªßi ro cao (Churn Score > 70%)
# L∆∞u √Ω: C·ªôt 'Churn_Score' ƒë√£ ƒë∆∞·ª£c t·∫°o ·ªü d√≤ng 41 trong code c≈© c·ªßa b·∫°n
# C·∫ßn c√≥ DataFrame ch·ª©a Churn_Score v√† c√°c c·ªôt kh√°c ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω
# Gi·∫£ ƒë·ªãnh: 'df_with_churn_score' l√† DataFrame ƒë√£ c√≥ c·ªôt 'Churn_Score' v√† c√°c ƒë·∫∑c tr∆∞ng
# V√¨ kh√¥ng c√≥ 'df_with_churn_score' ƒë∆∞·ª£c t·∫°o ·ªü ƒë√¢y, t√¥i s·∫Ω s·ª≠ d·ª•ng 'df' gi·∫£ ƒë·ªãnh t·ª´ cell tr∆∞·ªõc v√† t·∫°o c·ªôt 'Churn_Score' m·∫´u

# --- B·ªî SUNG: T·∫°o Churn_Score gi·∫£ ƒë·ªãnh v√† DataFrame 'df' n·∫øu ch∆∞a c√≥ --- 
# D·ª±a tr√™n kernel state, 'df' v√† 'Churn_Score' ch∆∞a t·ªìn t·∫°i tr·ª±c ti·∫øp trong cell n√†y.
# ƒê·ªÉ code ch·∫°y ƒë∆∞·ª£c, ta c·∫ßn t·∫°o 'df' v√† 'Churn_Score' t·ª´ 'X_data' v√† 'clf_model' ƒë√£ hu·∫•n luy·ªán.
# T√°i c·∫•u tr√∫c l·∫°i ƒë·ªÉ l·∫•y df t·ª´ context ho·∫∑c t·∫°o df gi·∫£ ƒë·ªãnh n·∫øu ƒë√¢y l√† m·ªôt ph·∫ßn ƒë·ªôc l·∫≠p

# L·∫•y d·ªØ li·ªáu m·∫´u ban ƒë·∫ßu ƒë·ªÉ t·∫°o l·∫°i DataFrame
# (Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ df_original t·ª´ b∆∞·ªõc 2 c·ªßa notebook ƒë·∫ßu ti√™n)
# N·∫øu kh√¥ng, c·∫ßn load l·∫°i ho·∫∑c truy·ªÅn v√†o t·ª´ c√°c cell tr∆∞·ªõc

# ƒê·ªÉ ƒë∆°n gi·∫£n v√† l√†m cho ph·∫ßn n√†y ch·∫°y ƒë∆∞·ª£c, t√¥i s·∫Ω m√¥ ph·ªèng l·∫°i df v√† Churn_Score
# THAY TH·∫æ B·∫∞NG C√ÅCH L·∫§Y CHURN_SCORE TH·∫¨T T·ª™ M√î H√åNH C·ª¶A B·∫†N!

# L·∫•y c√°c bi·∫øn t·ª´ m√¥i tr∆∞·ªùng global n·∫øu ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü c√°c cell tr∆∞·ªõc
# Gi·∫£ ƒë·ªãnh X_data, y_labels, clf_model, feature_names ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a

# T·∫°o l·∫°i DataFrame t∆∞∆°ng t·ª± df ban ƒë·∫ßu ƒë·ªÉ s·ª≠ d·ª•ng c√°c c·ªôt string
# ƒê√¢y l√† m·ªôt gi·∫£i ph√°p t·∫°m th·ªùi, c·∫ßn thay th·∫ø b·∫±ng DataFrame g·ªëc v·ªõi c√°c c·ªôt g·ªëc

# L·∫•y d·ªØ li·ªáu m·∫´u t·ª´ cell xuPLtbD6VpKh
data_sample = {
    'customerID': ['7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '2809-LSDNY'],
    'gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male'],
    'SeniorCitizen': [0, 0, 0, 0, 0, 0, 0],
    'Partner': ['Yes', 'No', 'No', 'No', 'No', 'No', 'No'],
    'Dependents': ['No', 'No', 'No', 'No', 'No', 'No', 'No'],
    'tenure': [1, 34, 2, 45, 2, 8, 22],
    'PhoneService': ['No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes'],
    'MultipleLines': ['No phone service', 'No', 'No', 'No phone service', 'No', 'No phone service', 'No'],
    'InternetService': ['DSL', 'DSL', 'DSL', 'DSL', 'Fiber optic', 'Fiber optic', 'DSL'],
    'Contract': ['Month-to-month', 'One year', 'Month-to-month', 'One year', 'Month-to-month', 'Month-to-month', 'Two year'],
    'MonthlyCharges': [29.85, 56.95, 53.85, 42.3, 70.7, 52.55, 20.25],
    'TotalCharges': ['29.85', '1889.5', '108.15', '1840.75', '151.65', '405.35', '458.55'],
    'Churn': ['No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No']
}
df_streamlit = pd.DataFrame(data_sample)

# Chuy·ªÉn ƒë·ªïi TotalCharges sang s·ªë
df_streamlit['TotalCharges'] = pd.to_numeric(df_streamlit['TotalCharges'], errors='coerce')
df_streamlit.fillna(df_streamlit.mean(numeric_only=True), inplace=True)

# S·ª≠ d·ª•ng preprocessor t·ª´ cell xuPLtbD6VpKh ƒë·ªÉ x·ª≠ l√Ω df_streamlit
# C·∫ßn ph·∫£i t·∫°o l·∫°i preprocessor n·∫øu kh√¥ng c√≥ s·∫µn trong global scope
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract']
numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']

preprocessor_for_inference = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', 'passthrough', numerical_features)
    ],
    remainder='drop'
)

# Fit preprocessor on dummy data to get consistent columns (or on training data originally)
# For this example, we fit it on the sample data itself
X_processed_sample = preprocessor_for_inference.fit_transform(df_streamlit.drop(['customerID', 'Churn'], axis=1))

# D·ª± ƒëo√°n churn score t·ª´ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (clf_model)
# Ch√∫ √Ω: clf_model c·∫ßn ph·∫£i c√≥ s·∫µn trong kernel state
if 'clf_model' in globals():
    churn_proba = clf_model.predict_proba(X_processed_sample)[:, 1]
    df_streamlit['Churn_Score'] = churn_proba
else:
    # Fallback n·∫øu clf_model kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y (ch·ªâ ƒë·ªÉ code ch·∫°y)
    df_streamlit['Churn_Score'] = np.random.rand(len(df_streamlit)) # M·∫´u ng·∫´u nhi√™n
    print("C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y 'clf_model', s·ª≠ d·ª•ng Churn_Score ng·∫´u nhi√™n.")

high_risk_customers = df_streamlit[df_streamlit['Churn_Score'] > 0.7].copy()

if high_risk_customers.empty:
    st.success("Tuy·ªát v·ªùi! Hi·ªán t·∫°i kh√¥ng c√≥ kh√°ch h√†ng n√†o trong nh√≥m r·ªßi ro cao.")
else:
    st.warning(f"‚ö†Ô∏è C·∫£nh b√°o: T√¨m th·∫•y **{len(high_risk_customers)}** kh√°ch h√†ng c√≥ nguy c∆° r·ªùi b·ªè SoftBank.")

    # 2. H√†m logic ƒë·ªÅ xu·∫•t ∆∞u ƒë√£i (SoftBank Recommendation Engine)
    def generate_softbank_offer(row):
        offers = [] # Kh·ªüi t·∫°o danh s√°ch offers

        # K·ªãch b·∫£n 1: Gi√° c∆∞·ªõc cao + H·ª£p ƒë·ªìng ng·∫Øn h·∫°n -> ƒê·ªÅ xu·∫•t g√≥i c∆∞·ªõc r·∫ª h∆°n (LINEMO/Y!mobile)
        if row['MonthlyCharges'] > 80 and row['Contract'] == 'Month-to-month':
            offers.append("üìâ Chuy·ªÉn sang **LINEMO** (20GB) ho·∫∑c **Y!mobile**")
            offers.append("üí∞ T·∫∑ng 3,000 ƒëi·ªÉm **PayPay** n·∫øu gia h·∫°n")

        # K·ªãch b·∫£n 2: D√πng Fiber Optic -> TƒÉng g·∫Øn k·∫øt b·∫±ng h·ªá sinh th√°i (ƒêi·ªán + Net)
        # S·ª≠a l·ªói: C·∫ßn ki·ªÉm tra c·ªôt 'InternetService' ch·ª© kh√¥ng ph·∫£i 'row' tr·ª±c ti·∫øp
        elif row['InternetService'] == 'Fiber optic':
            offers.append("üè† K√≠ch ho·∫°t **Ouchi Wari** (Gi·∫£m gi√° Combo ƒêi·ªán/Net)")
            offers.append("üéÅ T·∫∑ng Yahoo! Premium mi·ªÖn ph√≠ 6 th√°ng")

        # K·ªãch b·∫£n 3: C√≥ g·ªçi h·ªó tr·ª£ k·ªπ thu·∫≠t -> C·∫ßn chƒÉm s√≥c ƒë·∫∑c bi·ªát
        # S·ª≠a l·ªói: C·∫ßn m·ªôt c·ªôt c·ª• th·ªÉ ƒë·ªÉ ki·ªÉm tra vi·ªác g·ªçi h·ªó tr·ª£ k·ªπ thu·∫≠t, v√≠ d·ª• 'TechSupport'
        # Gi·∫£ s·ª≠ c√≥ c·ªôt 'TechSupport' v√† gi√° tr·ªã 'Yes' bi·ªÉu th·ªã c√≥ h·ªó tr·ª£
        # N·∫øu kh√¥ng c√≥, c·∫ßn b·ªï sung c·ªôt n√†y v√†o d·ªØ li·ªáu ho·∫∑c d√πng logic kh√°c
        elif 'TechSupport' in row and row['TechSupport'] == 'Yes': # Thay 'row == 'Yes'' b·∫±ng logic h·ª£p l·ªá
            offers.append("üìû **Priority Call:** CSKH g·ªçi l·∫°i h·ªó tr·ª£ trong 1h")
            offers.append("üîß Ki·ªÉm tra thi·∫øt b·ªã mi·ªÖn ph√≠ t·∫°i SoftBank Shop")

        # K·ªãch b·∫£n 4: Kh√°ch h√†ng l√¢u nƒÉm (> 2 nƒÉm) -> Tri √¢n
        elif row['tenure'] > 24:
            offers.append("üíé N√¢ng h·∫°ng **SoftBank Premium**")
            offers.append("üéüÔ∏è T·∫∑ng v√© xem b√≥ng ch√†y (SoftBank Hawks)")

        # M·∫∑c ƒë·ªãnh cho c√°c nh√≥m c√≤n l·∫°i
        else:
            offers.append("üì© T·∫∑ng Coupon 500 Y√™n qua ·ª©ng d·ª•ng My SoftBank")

        return " + ".join(offers)

    # √Åp d·ª•ng h√†m tr√™n v√†o d·ªØ li·ªáu
    # S·ª≠ d·ª•ng st.spinner ƒë·ªÉ b√°o hi·ªáu ƒëang x·ª≠ l√Ω
    with st.spinner('ƒêang ph√¢n t√≠ch h√†nh vi v√† t·∫°o ƒë·ªÅ xu·∫•t...'):
        # C·∫ßn t·∫°o m·ªôt c·ªôt m·ªõi ƒë·ªÉ l∆∞u tr·ªØ c√°c ƒë·ªÅ xu·∫•t
        high_risk_customers['Offer_Recommendation'] = high_risk_customers.apply(generate_softbank_offer, axis=1)

    # 3. Hi·ªÉn th·ªã b·∫£ng h√†nh ƒë·ªông
    col1, col2 = st.columns([1, 2])

    with col1:
        st.subheader("üìã Danh s√°ch h√†nh ƒë·ªông c·ª• th·ªÉ")
        # Ch·ªâ hi·ªán c√°c c·ªôt quan tr·ªçng ƒë·ªÉ nh√¢n vi√™n d·ªÖ nh√¨n
        display_cols = ['customerID', 'Churn_Score', 'Offer_Recommendation', 'tenure', 'MonthlyCharges', 'Contract', 'InternetService']
        # Ki·ªÉm tra xem c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng tr∆∞·ªõc khi hi·ªÉn th·ªã ƒë·ªÉ tr√°nh l·ªói
        valid_cols = [c for c in display_cols if c in high_risk_customers.columns]
        st.dataframe(high_risk_customers[valid_cols])

    with col2:
        st.subheader("üìä Th·ªëng k√™ gi·∫£i ph√°p")
        # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i gi·∫£i ph√°p ch√≠nh
        # C·∫ßn ƒë·∫øm tr√™n c·ªôt 'Offer_Recommendation'
        action_counts = high_risk_customers['Offer_Recommendation'].value_counts().head(5)
        st.bar_chart(action_counts)

    # 4. T√≠nh nƒÉng GenAI (M√¥ ph·ªèng so·∫°n Email)
    st.markdown("### üìß So·∫°n th·∫£o Email t·ª± ƒë·ªông (GenAI Simulation)")

    # Ch·ªçn kh√°ch h√†ng t·ª´ danh s√°ch r·ªßi ro
    # S·ª≠a l·ªói: selectbox c·∫ßn m·ªôt list c√°c gi√° tr·ªã ƒë·ªÉ ch·ªçn
    selected_cust_id = st.selectbox("Ch·ªçn ID kh√°ch h√†ng ƒë·ªÉ g·ª≠i ∆∞u ƒë√£i:", high_risk_customers['customerID'].tolist())

    if selected_cust_id:
        # L·∫•y th√¥ng tin d√≤ng d·ªØ li·ªáu c·ªßa kh√°ch h√†ng ƒë√≥
        # S·ª≠a l·ªói: L·∫•y d√≤ng d·ª±a tr√™n customerID v√† .iloc[0] ƒë·ªÉ c√≥ Series
        cust_info = high_risk_customers[high_risk_customers['customerID'] == selected_cust_id].iloc[0]

        # So·∫°n n·ªôi dung email
        email_content = f"""
        ----------------------------------------------------
        **To:** {cust_info['customerID']}@softbank.ne.jp
        **Subject:** ∆Øu ƒë√£i ƒë·∫∑c bi·ªát d√†nh ri√™ng cho b·∫°n!

        K√≠nh g·ª≠i Qu√Ω kh√°ch,

        C·∫£m ∆°n b·∫°n ƒë√£ g·∫Øn b√≥ v·ªõi SoftBank su·ªët {cust_info['tenure']} th√°ng qua.
        H·ªá th·ªëng nh·∫≠n th·∫•y b·∫°n ƒëang g·∫∑p m·ªôt s·ªë b·∫•t ti·ªán (ƒêi·ªÉm r·ªßi ro: {cust_info['Churn_Score']:.2f}).

        Ch√∫ng t√¥i xin g·ª≠i t·∫∑ng b·∫°n g√≥i ∆∞u ƒë√£i ƒë∆∞·ª£c thi·∫øt k·∫ø ri√™ng:
        üëâ {cust_info['Offer_Recommendation']}

        Vui l√≤ng m·ªü ·ª©ng d·ª•ng PayPay ƒë·ªÉ nh·∫≠n ngay.
        ----------------------------------------------------
        """
        st.code(email_content, language='text')

        if st.button("üöÄ G·ª≠i Email Gi·ªØ Ch√¢n"):
            st.success(f"ƒê√£ g·ª≠i ∆∞u ƒë√£i th√†nh c√¥ng t·ªõi kh√°ch h√†ng {selected_cust_id}!")
#!pip install streamlit
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. Logic G·ª£i √Ω Gi·∫£i ph√°p AI (Gi·∫£i ph√°p Gi·ªØ ch√¢n) ---
def suggest_retention_strategy(row):
    """
    H√†m n√†y ƒë·∫°i di·ªán cho logic nghi·ªáp v·ª• sau khi AI d·ª± ƒëo√°n.
    N√≥ ƒë∆∞a ra gi·∫£i ph√°p gi·ªØ ch√¢n C√Å NH√ÇN H√ìA d·ª±a tr√™n Churn Score v√† c√°c ƒë·∫∑c ƒëi·ªÉm r·ªßi ro ch√≠nh.
    """
    score = row['Churn_Score'] # Access Churn_Score from the row
    # S·ª≠ d·ª•ng c√°c c·ªôt th√¥ t·ª´ DataFrame
    contract = row.get('Contract', 'Month-to-month')
    charges = row.get('MonthlyCharges', 0)
    tenure = row.get('tenure', 0)
    internet = row.get('InternetService', 'No')

    # Logic ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa Fiber Optic (t·ª´ c·ªôt InternetService th√¥)
    is_fiber = (internet == 'Fiber optic')

    # LOGIC ƒê·ªÄ XU·∫§T GI·∫¢I PH√ÅP

    if score >= 0.75:
        # Nh√≥m R·ª¶I RO C·ª∞C CAO (∆Øu ti√™n can thi·ªáp b·∫±ng nh√¢n vi√™n)
        if contract == 'Month-to-month' and is_fiber:
            return "∆Øu ƒë√£i V√†ng: N√¢ng c·∫•p mi·ªÖn ph√≠ l√™n g√≥i 1 nƒÉm (gi·∫£m 15% c∆∞·ªõc) + T·∫∑ng th√™m 5GB Data. (CSO g·ªçi ƒëi·ªán)"
        elif charges > 100 and tenure < 12:
            return "Gi·∫£m c∆∞·ªõc th√°ng 20% trong 6 th√°ng ƒë·∫ßu + ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng d·ªãch v·ª• Internet. (Team Sales)"
        elif tenure > 60 and contract == 'Month-to-month':
             return "G√≥i B·∫£o hi·ªÉm Thi·∫øt b·ªã mi·ªÖn ph√≠ 12 th√°ng + Th∆∞ xin l·ªói c√° nh√¢n h√≥a. (Team H·ªó tr·ª£)"
        else:
            return "G√≥i d·ªãch v·ª• ƒë·ªôc quy·ªÅn Softbank/PayPay mi·ªÖn ph√≠ 3 th√°ng. (Team Marketing)"

    elif 0.5 <= score < 0.75:
        # Nh√≥m R·ª¶I RO CAO (S·ª≠ d·ª•ng t·ª± ƒë·ªông h√≥a)
        if contract == 'Month-to-month':
            return "ƒê·ªÅ xu·∫•t chuy·ªÉn ƒë·ªïi sang H·ª£p ƒë·ªìng 1 nƒÉm v·ªõi ∆∞u ƒë√£i data/t·ªëc ƒë·ªô tƒÉng g·∫•p ƒë√¥i. (G·ª≠i th√¥ng b√°o App/SMS)"
        elif internet == 'DSL':
            return "ƒê·ªÅ xu·∫•t n√¢ng c·∫•p l√™n Fiber v·ªõi gi√° ∆∞u ƒë√£i trong 6 th√°ng. (Email Marketing t·ª± ƒë·ªông)"
        else:
            return "Kh·∫£o s√°t ng·∫Øn CSAT v·ªÅ ch·∫•t l∆∞·ª£ng d·ªãch v·ª• hi·ªán t·∫°i. (Pop-up trong ·ª©ng d·ª•ng)"

    else:
        # Nh√≥m R·ª¶ RO TH·∫§P (Theo d√µi ƒë·ªãnh k·ª≥)
        return "Theo d√µi ƒë·ªãnh k·ª≥ 30 ng√†y. G·ª≠i n·ªôi dung gi√° tr·ªã (How-to, m·∫πo s·ª≠ d·ª•ng) ƒë·ªÉ tƒÉng g·∫Øn k·∫øt."

# --- B·∫Øt ƒë·∫ßu Khung Streamlit c·ªßa b·∫°n ---

# T·∫£i model, scaler v√† feature_names
try:
    with open("model.pkl", "rb") as f:
        model = pickle.load(f)
    with open("scaler.pkl", "rb") as f:
        scaler = pickle.load(f)
    with open("feature_names.pkl", "rb") as f:
        feature_names = pickle.load(f)
except FileNotFoundError:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file model.pkl, scaler.pkl, ho·∫∑c feature_names.pkl. Vui l√≤ng ch·∫°y file hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
    st.stop()


st.title("üìä D·ª± ƒëo√°n t·ª∑ l·ªá kh√°ch h√†ng r·ªùi b·ªè d·ªãch v·ª• AI - SOFTBANK")
st.write("D·ª± ƒëo√°n kh√°ch h√†ng c√≥ th·ªÉ b·ªè ho·∫∑c kh√¥ng d·ª±a v√†o Machine Learning m√¥ h√¨nh")
st.markdown("---")


uploaded_file = st.file_uploader("üì• T·∫£i t·ªáp CSV Telco Customer Churn", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.subheader("üìÑ ƒê·∫ßu v√†o D·ªØ li·ªáu:")
    st.dataframe(df.head())

    # ------------------------------------------------
    # 23-40: KHUNG X·ª¨ L√ù V√Ä D·ª∞ ƒêO√ÅN (CODE G·ªêC C·ª¶A B·∫†N)
    # ------------------------------------------------

    # Make a copy for processing to retain original df for potential other uses
    df_for_processing = df.copy()

    # Convert 'TotalCharges' to numeric, handling missing values
    # Assuming 'TotalCharges' is the only column that might contain non-numeric data
    # (e.g., spaces for new customers), and other numeric columns are already clean.
    if 'TotalCharges' in df_for_processing.columns:
        df_for_processing['TotalCharges'] = pd.to_numeric(df_for_processing['TotalCharges'], errors='coerce')

    # Drop rows with NaNs (e.g., from 'TotalCharges' conversion or other missing data)
    # It's important to keep track of the original indices if customerID is not unique
    # or if we need to map back to the original `df`.
    # For simplicity, we will drop NaNs and assume the index aligns.
    df_for_processing.dropna(inplace=True)

    # Store a version of the DataFrame that will contain results (customer details + churn score)
    # This ensures we have customer details like Contract, MonthlyCharges, tenure, InternetService
    # for the `suggest_retention_strategy` function.
    results_df = df_for_processing.copy()

    # Columns to drop from features used for prediction.
    # Based on the comment, 'Gender' is not used. 'customerID' is an identifier.
    # Other raw categorical features will be one-hot encoded.
    columns_to_drop_from_features = ['customerID', 'gender'] # Add 'gender' as per comment
    df_features = df_for_processing.drop(columns=columns_to_drop_from_features, errors='ignore')

    # M√£ h√≥a One-Hot cho c√°c bi·∫øn ph√¢n lo·∫°i ƒë·ªÉ chu·∫©n b·ªã cho m√¥ h√¨nh
    df_processed = pd.get_dummies(df_features, drop_first=True)

    # ƒê·ªìng b·ªô v·ªõi c·ªôt c·ªßa m√¥ h√¨nh
    missing_cols = set(feature_names) - set(df_processed.columns)
    for c in missing_cols:
        df_processed[c] = 0
    df_processed = df_processed[feature_names]

    # T·ªâ l·ªá
    X_scaled = scaler.transform(df_processed)

    # D·ª± ƒëo√°n
    proba = model.predict_proba(X_scaled)[:, 1]

    # G·∫Øn Churn Score v√†o DataFrame k·∫øt qu·∫£
    results_df['Churn_Score'] = proba


    # ------------------------------------------------
    # 41-48: HI·ªÇN TH·ªä K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN (CODE G·ªêC C·ª¶A B·∫†N)
    # ------------------------------------------------

    st.subheader("üîç K·∫øt qu·∫£ D·ª± ƒëo√°n:")
    # Use results_df for display
    st.dataframe(results_df.sort_values(by="Churn_Score", ascending=False).head(10))

    st.subheader("üî• Kh√°ch h√†ng c√≥ nguy c∆° cao (Churn > 0.7):")
    # Filter results_df directly
    high_risk_customers_df = results_df[results_df['Churn_Score'] > 0.7].copy()

    st.dataframe(
        high_risk_customers_df,
        column_config={
             "Churn_Score": st.column_config.ProgressColumn("Churn Score", format="%.2f", min_value=0.0, max_value=1.0)
        },
        use_container_width=True
    )

    # ------------------------------------------------
    # --- B·ªî SUNG Y√äU C·∫¶U 1: PH√ÇN T√çCH ƒê·ªòNG L·ª∞C CHURN (FEATURE IMPORTANCE) ---
    # ------------------------------------------------

    st.markdown("---")
    st.header("1. Ph√¢n T√≠ch ƒê·ªông L·ª±c Churn (Nguy√™n nh√¢n Kh√°ch h√†ng R·ªùi b·ªè)")

    # L·∫•y Feature Importance t·ª´ m√¥ h√¨nh ƒë√£ load
    importances = model.feature_importances_
    feature_imp_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importances
    }).sort_values('Importance', ascending=False).head(10)

    fig, ax = plt.subplots(figsize=(10, 5))
    sns.barplot(x='Importance', y='Feature', data=feature_imp_df, palette="magma", ax=ax)
    ax.set_title('Top 10 ƒê·∫∑c tr∆∞ng Quan tr·ªçng D·ª± ƒëo√°n Churn (Gini Importance)')
    ax.set_xlabel('ƒêi·ªÉm Quan tr·ªçng')
    ax.set_ylabel('ƒê·∫∑c tr∆∞ng Kh√°ch h√†ng')
    st.pyplot(fig)
    #

    st.markdown("""
    **H∆∞·ªõng Kh·∫Øc ph·ª•c T·ªïng quan d·ª±a tr√™n Ph√¢n t√≠ch ƒê·∫∑c tr∆∞ng:**
    1. **H·ª£p ƒë·ªìng ng·∫Øn h·∫°n (`Contract_Month-to-month`):** Lu√¥n l√† y·∫øu t·ªë r·ªßi ro h√†ng ƒë·∫ßu. **Gi·∫£i ph√°p:** T·∫≠p trung chi·∫øn d·ªãch chuy·ªÉn ƒë·ªïi kh√°ch h√†ng n√†y sang h·ª£p ƒë·ªìng 1 ho·∫∑c 2 nƒÉm v·ªõi c√°c ∆∞u ƒë√£i g·∫Øn k·∫øt (bundle, PayPay points [2]).
    2. **Th·ªùi gian G·∫Øn b√≥ (`tenure`):** Kh√°ch h√†ng r·∫•t m·ªõi (tenure th·∫•p) ho·∫∑c m·ªõi b·∫Øt ƒë·∫ßu c√≥ r·ªßi ro cao. **Gi·∫£i ph√°p:** TƒÉng c∆∞·ªùng ch∆∞∆°ng tr√¨nh Onboarding/CSM ch·ªß ƒë·ªông trong 90 ng√†y ƒë·∫ßu ti√™n ƒë·ªÉ ƒë·∫£m b·∫£o s·ª± h√†i l√≤ng v·ªõi ch·∫•t l∆∞·ª£ng m·∫°ng v√† h√≥a ƒë∆°n.
    3. **D·ªãch v·ª• Fiber Optic:** Kh√°ch h√†ng tr·∫£ ph√≠ cao c√≥ k·ª≥ v·ªçng cao h∆°n. **Gi·∫£i ph√°p:** √Åp d·ª•ng gi√°m s√°t ch·ªß ƒë·ªông (proactive monitoring) ƒë·ªÉ kh·∫Øc ph·ª•c c√°c s·ª± c·ªë m·∫°ng ti·ªÅm ·∫©n tr∆∞·ªõc khi kh√°ch h√†ng ph√†n n√†n.[1]
    """)

    # ------------------------------------------------
    # --- B·ªî SUNG Y√äU C·∫¶U 2: GI·∫¢I PH√ÅP C√Å NH√ÇN H√ìA V√Ä PH√ÇN T√çCH T√ÅC ƒê·ªòNG ---
    # ------------------------------------------------

    st.markdown("---")
    st.header("2. Gi·∫£i Ph√°p Gi·ªØ Ch√¢n C√° Nh√¢n H√≥a (AI Retention Strategy)")

    # Thi·∫øt l·∫≠p ng∆∞·ª°ng r·ªßi ro c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh
    risk_threshold = st.slider("Ch·ªçn Ng∆∞·ª°ng Churn Score T·ªëi Thi·ªÉu ƒë·ªÉ Can Thi·ªáp:",
                      min_value=0.5, max_value=0.9, value=0.70, step=0.05)

    # L·ªçc l·∫°i danh s√°ch kh√°ch h√†ng r·ªßi ro cao theo ng∆∞·ª°ng m·ªõi
    high_risk_strategies_df = results_df[results_df['Churn_Score'] >= risk_threshold].copy()
    high_risk_strategies_df['Retention_Strategy'] = high_risk_strategies_df.apply(suggest_retention_strategy, axis=1)

    st.dataframe(
        high_risk_strategies_df[['customerID', 'Churn_Score', 'Retention_Strategy']], # Display relevant columns
        height=300,
        use_container_width=True,
        column_config={
             "Churn_Score": st.column_config.ProgressColumn("Churn Score", format="%.2f", min_value=0.0, max_value=1.0),
             "Retention_Strategy": st.column_config.TextColumn("Gi·∫£i Ph√°p Gi·ªØ Ch√¢n ƒê·ªÅ Xu·∫•t (AI)", width="large")
        }
    )

    # Bi·ªÉu ƒë·ªì Ph√¢n b·ªï Gi·∫£i ph√°p (ƒê·ªÉ hi·ªÉu c·∫ßn ph√¢n b·ªï ng√¢n s√°ch cho lo·∫°i chi·∫øn d·ªãch n√†o)
    st.subheader("Ph√¢n b·ªï T·∫ßn su·∫•t c√°c Gi·∫£i ph√°p AI ƒê·ªÅ xu·∫•t:")

    if not high_risk_strategies_df.empty:
        # Extract just the strategy description before the parentheses
        strategy_counts = high_risk_strategies_df['Retention_Strategy'].apply(lambda x: x.split('(')[0].strip()).value_counts().head(5)

        fig_strat, ax_strat = plt.subplots(figsize=(8, 4))
        strategy_counts.plot(kind='barh', ax=ax_strat, color='teal')
        ax_strat.set_title('Top 5 Lo·∫°i Gi·∫£i ph√°p c·∫ßn ∆∞u ti√™n')
        ax_strat.set_xlabel('S·ªë l∆∞·ª£ng Kh√°ch h√†ng M·ª•c ti√™u')
        plt.gca().invert_yaxis()
        st.pyplot(fig_strat)
    else:
        st.info("Kh√¥ng c√≥ kh√°ch h√†ng n√†o ƒë·∫°t ng∆∞·ª°ng r·ªßi ro n√†y ƒë·ªÉ ƒë·ªÅ xu·∫•t gi·∫£i ph√°p.")
