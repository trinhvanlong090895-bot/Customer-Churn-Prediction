import streamlit as st
import pandas as pd
import numpy as np
import pickle

st.title("ğŸ“Š AI Customer Churn Prediction")
st.write("Dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng cÃ³ rá»i bá» hay khÃ´ng dá»±a trÃªn mÃ´ hÃ¬nh Machine Learning")

# Load model, scaler vÃ  feature_names
model = pickle.load(open("model.pkl", "rb"))
scaler = pickle.load(open("scaler.pkl", "rb"))
feature_names = pickle.load(open("feature_names.pkl", "rb"))  # â† ThÃªm dÃ²ng nÃ y

uploaded_file = st.file_uploader("ğŸ“¥ Táº£i file CSV Telco Customer Churn", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    st.subheader("ğŸ“„ Dá»¯ liá»‡u Ä‘áº§u vÃ o:")
    st.dataframe(df.head())

    # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
    df = df.dropna()

    df_processed = pd.get_dummies(df, drop_first=True)

    # Äá»“ng bá»™ vá»›i cá»™t cá»§a model
    missing_cols = set(feature_names) - set(df_processed.columns)  # â† Sá»­a dÃ²ng nÃ y
    for c in missing_cols:
        df_processed[c] = 0

    df_processed = df_processed[feature_names]  # â† Sá»­a dÃ²ng nÃ y

    # Scale
    X_scaled = scaler.transform(df_processed)

    # Predict
    proba = model.predict_proba(X_scaled)[:, 1]

    df["Churn_Score"] = proba

    st.subheader("ğŸ” Káº¿t quáº£ dá»± Ä‘oÃ¡n:")
    st.dataframe(df.sort_values(by="Churn_Score", ascending=False))

    st.subheader("ğŸ”¥ KhÃ¡ch hÃ ng cÃ³ nguy cÆ¡ cao (Churn > 0.7):")
    st.dataframe(df[df["Churn_Score"] > 0.7])

    st.bar_chart(df["Churn_Score"])
# --- Báº®T Äáº¦U PHáº¦N CODE Má»šI (DÃ¡n tiáº¿p theo dÃ²ng 49) ---

st.markdown("---")
st.title("ğŸ›¡ï¸ Chiáº¿n lÆ°á»£c Giá»¯ chÃ¢n KhÃ¡ch hÃ ng (SoftBank Action Center)")

# 1. Lá»c danh sÃ¡ch khÃ¡ch hÃ ng rá»§i ro cao (Churn Score > 70%)
# LÆ°u Ã½: Cá»™t 'Churn_Score' Ä‘Ã£ Ä‘Æ°á»£c táº¡o á»Ÿ dÃ²ng 41 trong code cÅ© cá»§a báº¡n
# Cáº§n cÃ³ DataFrame chá»©a Churn_Score vÃ  cÃ¡c cá»™t khÃ¡c Ä‘Ã£ Ä‘Æ°á»£c tiá»n xá»­ lÃ½
# Giáº£ Ä‘á»‹nh: 'df_with_churn_score' lÃ  DataFrame Ä‘Ã£ cÃ³ cá»™t 'Churn_Score' vÃ  cÃ¡c Ä‘áº·c trÆ°ng
# VÃ¬ khÃ´ng cÃ³ 'df_with_churn_score' Ä‘Æ°á»£c táº¡o á»Ÿ Ä‘Ã¢y, tÃ´i sáº½ sá»­ dá»¥ng 'df' giáº£ Ä‘á»‹nh tá»« cell trÆ°á»›c vÃ  táº¡o cá»™t 'Churn_Score' máº«u

# --- Bá»” SUNG: Táº¡o Churn_Score giáº£ Ä‘á»‹nh vÃ  DataFrame 'df' náº¿u chÆ°a cÃ³ --- 
# Dá»±a trÃªn kernel state, 'df' vÃ  'Churn_Score' chÆ°a tá»“n táº¡i trá»±c tiáº¿p trong cell nÃ y.
# Äá»ƒ code cháº¡y Ä‘Æ°á»£c, ta cáº§n táº¡o 'df' vÃ  'Churn_Score' tá»« 'X_data' vÃ  'clf_model' Ä‘Ã£ huáº¥n luyá»‡n.
# TÃ¡i cáº¥u trÃºc láº¡i Ä‘á»ƒ láº¥y df tá»« context hoáº·c táº¡o df giáº£ Ä‘á»‹nh náº¿u Ä‘Ã¢y lÃ  má»™t pháº§n Ä‘á»™c láº­p

# Láº¥y dá»¯ liá»‡u máº«u ban Ä‘áº§u Ä‘á»ƒ táº¡o láº¡i DataFrame
# (Giáº£ sá»­ báº¡n Ä‘Ã£ cÃ³ df_original tá»« bÆ°á»›c 2 cá»§a notebook Ä‘áº§u tiÃªn)
# Náº¿u khÃ´ng, cáº§n load láº¡i hoáº·c truyá»n vÃ o tá»« cÃ¡c cell trÆ°á»›c

# Äá»ƒ Ä‘Æ¡n giáº£n vÃ  lÃ m cho pháº§n nÃ y cháº¡y Ä‘Æ°á»£c, tÃ´i sáº½ mÃ´ phá»ng láº¡i df vÃ  Churn_Score
# THAY THáº¾ Báº°NG CÃCH Láº¤Y CHURN_SCORE THáº¬T Tá»ª MÃ” HÃŒNH Cá»¦A Báº N!

# Láº¥y cÃ¡c biáº¿n tá»« mÃ´i trÆ°á»ng global náº¿u Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a á»Ÿ cÃ¡c cell trÆ°á»›c
# Giáº£ Ä‘á»‹nh X_data, y_labels, clf_model, feature_names Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a

# Táº¡o láº¡i DataFrame tÆ°Æ¡ng tá»± df ban Ä‘áº§u Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c cá»™t string
# ÄÃ¢y lÃ  má»™t giáº£i phÃ¡p táº¡m thá»i, cáº§n thay tháº¿ báº±ng DataFrame gá»‘c vá»›i cÃ¡c cá»™t gá»‘c

# Láº¥y dá»¯ liá»‡u máº«u tá»« cell xuPLtbD6VpKh
data_sample = {
    'customerID': ['7590-VHVEG', '5575-GNVDE', '3668-QPYBK', '7795-CFOCW', '9237-HQITU', '9305-CDSKC', '2809-LSDNY'],
    'gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male'],
    'SeniorCitizen': [0, 0, 0, 0, 0, 0, 0],
    'Partner': ['Yes', 'No', 'No', 'No', 'No', 'No', 'No'],
    'Dependents': ['No', 'No', 'No', 'No', 'No', 'No', 'No'],
    'tenure': [1, 34, 2, 45, 2, 8, 22],
    'PhoneService': ['No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes'],
    'MultipleLines': ['No phone service', 'No', 'No', 'No phone service', 'No', 'No phone service', 'No'],
    'InternetService': ['DSL', 'DSL', 'DSL', 'DSL', 'Fiber optic', 'Fiber optic', 'DSL'],
    'Contract': ['Month-to-month', 'One year', 'Month-to-month', 'One year', 'Month-to-month', 'Month-to-month', 'Two year'],
    'MonthlyCharges': [29.85, 56.95, 53.85, 42.3, 70.7, 52.55, 20.25],
    'TotalCharges': ['29.85', '1889.5', '108.15', '1840.75', '151.65', '405.35', '458.55'],
    'Churn': ['No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No']
}
df_streamlit = pd.DataFrame(data_sample)

# Chuyá»ƒn Ä‘á»•i TotalCharges sang sá»‘
df_streamlit['TotalCharges'] = pd.to_numeric(df_streamlit['TotalCharges'], errors='coerce')
df_streamlit.fillna(df_streamlit.mean(numeric_only=True), inplace=True)

# Sá»­ dá»¥ng preprocessor tá»« cell xuPLtbD6VpKh Ä‘á»ƒ xá»­ lÃ½ df_streamlit
# Cáº§n pháº£i táº¡o láº¡i preprocessor náº¿u khÃ´ng cÃ³ sáºµn trong global scope
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract']
numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']

preprocessor_for_inference = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', 'passthrough', numerical_features)
    ],
    remainder='drop'
)

# Fit preprocessor on dummy data to get consistent columns (or on training data originally)
# For this example, we fit it on the sample data itself
X_processed_sample = preprocessor_for_inference.fit_transform(df_streamlit.drop(['customerID', 'Churn'], axis=1))

# Dá»± Ä‘oÃ¡n churn score tá»« mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (clf_model)
# ChÃº Ã½: clf_model cáº§n pháº£i cÃ³ sáºµn trong kernel state
if 'clf_model' in globals():
    churn_proba = clf_model.predict_proba(X_processed_sample)[:, 1]
    df_streamlit['Churn_Score'] = churn_proba
else:
    # Fallback náº¿u clf_model khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y (chá»‰ Ä‘á»ƒ code cháº¡y)
    df_streamlit['Churn_Score'] = np.random.rand(len(df_streamlit)) # Máº«u ngáº«u nhiÃªn
    print("Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y 'clf_model', sá»­ dá»¥ng Churn_Score ngáº«u nhiÃªn.")

high_risk_customers = df_streamlit[df_streamlit['Churn_Score'] > 0.7].copy()

if high_risk_customers.empty:
    st.success("Tuyá»‡t vá»i! Hiá»‡n táº¡i khÃ´ng cÃ³ khÃ¡ch hÃ ng nÃ o trong nhÃ³m rá»§i ro cao.")
else:
    st.warning(f"âš ï¸ Cáº£nh bÃ¡o: TÃ¬m tháº¥y **{len(high_risk_customers)}** khÃ¡ch hÃ ng cÃ³ nguy cÆ¡ rá»i bá» SoftBank.")

    # 2. HÃ m logic Ä‘á» xuáº¥t Æ°u Ä‘Ã£i (SoftBank Recommendation Engine)
    def generate_softbank_offer(row):
        offers = [] # Khá»Ÿi táº¡o danh sÃ¡ch offers

        # Ká»‹ch báº£n 1: GiÃ¡ cÆ°á»›c cao + Há»£p Ä‘á»“ng ngáº¯n háº¡n -> Äá» xuáº¥t gÃ³i cÆ°á»›c ráº» hÆ¡n (LINEMO/Y!mobile)
        if row['MonthlyCharges'] > 80 and row['Contract'] == 'Month-to-month':
            offers.append("ğŸ“‰ Chuyá»ƒn sang **LINEMO** (20GB) hoáº·c **Y!mobile**")
            offers.append("ğŸ’° Táº·ng 3,000 Ä‘iá»ƒm **PayPay** náº¿u gia háº¡n")

        # Ká»‹ch báº£n 2: DÃ¹ng Fiber Optic -> TÄƒng gáº¯n káº¿t báº±ng há»‡ sinh thÃ¡i (Äiá»‡n + Net)
        # Sá»­a lá»—i: Cáº§n kiá»ƒm tra cá»™t 'InternetService' chá»© khÃ´ng pháº£i 'row' trá»±c tiáº¿p
        elif row['InternetService'] == 'Fiber optic':
            offers.append("ğŸ  KÃ­ch hoáº¡t **Ouchi Wari** (Giáº£m giÃ¡ Combo Äiá»‡n/Net)")
            offers.append("ğŸ Táº·ng Yahoo! Premium miá»…n phÃ­ 6 thÃ¡ng")

        # Ká»‹ch báº£n 3: CÃ³ gá»i há»— trá»£ ká»¹ thuáº­t -> Cáº§n chÄƒm sÃ³c Ä‘áº·c biá»‡t
        # Sá»­a lá»—i: Cáº§n má»™t cá»™t cá»¥ thá»ƒ Ä‘á»ƒ kiá»ƒm tra viá»‡c gá»i há»— trá»£ ká»¹ thuáº­t, vÃ­ dá»¥ 'TechSupport'
        # Giáº£ sá»­ cÃ³ cá»™t 'TechSupport' vÃ  giÃ¡ trá»‹ 'Yes' biá»ƒu thá»‹ cÃ³ há»— trá»£
        # Náº¿u khÃ´ng cÃ³, cáº§n bá»• sung cá»™t nÃ y vÃ o dá»¯ liá»‡u hoáº·c dÃ¹ng logic khÃ¡c
        elif 'TechSupport' in row and row['TechSupport'] == 'Yes': # Thay 'row == 'Yes'' báº±ng logic há»£p lá»‡
            offers.append("ğŸ“ **Priority Call:** CSKH gá»i láº¡i há»— trá»£ trong 1h")
            offers.append("ğŸ”§ Kiá»ƒm tra thiáº¿t bá»‹ miá»…n phÃ­ táº¡i SoftBank Shop")

        # Ká»‹ch báº£n 4: KhÃ¡ch hÃ ng lÃ¢u nÄƒm (> 2 nÄƒm) -> Tri Ã¢n
        elif row['tenure'] > 24:
            offers.append("ğŸ’ NÃ¢ng háº¡ng **SoftBank Premium**")
            offers.append("ğŸŸï¸ Táº·ng vÃ© xem bÃ³ng chÃ y (SoftBank Hawks)")

        # Máº·c Ä‘á»‹nh cho cÃ¡c nhÃ³m cÃ²n láº¡i
        else:
            offers.append("ğŸ“© Táº·ng Coupon 500 YÃªn qua á»©ng dá»¥ng My SoftBank")

        return " + ".join(offers)

    # Ãp dá»¥ng hÃ m trÃªn vÃ o dá»¯ liá»‡u
    # Sá»­ dá»¥ng st.spinner Ä‘á»ƒ bÃ¡o hiá»‡u Ä‘ang xá»­ lÃ½
    with st.spinner('Äang phÃ¢n tÃ­ch hÃ nh vi vÃ  táº¡o Ä‘á» xuáº¥t...'):
        # Cáº§n táº¡o má»™t cá»™t má»›i Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c Ä‘á» xuáº¥t
        high_risk_customers['Offer_Recommendation'] = high_risk_customers.apply(generate_softbank_offer, axis=1)

    # 3. Hiá»ƒn thá»‹ báº£ng hÃ nh Ä‘á»™ng
    col1, col2 = st.columns([1, 2])

    with col1:
        st.subheader("ğŸ“‹ Danh sÃ¡ch hÃ nh Ä‘á»™ng cá»¥ thá»ƒ")
        # Chá»‰ hiá»‡n cÃ¡c cá»™t quan trá»ng Ä‘á»ƒ nhÃ¢n viÃªn dá»… nhÃ¬n
        display_cols = ['customerID', 'Churn_Score', 'Offer_Recommendation', 'tenure', 'MonthlyCharges', 'Contract', 'InternetService']
        # Kiá»ƒm tra xem cÃ¡c cá»™t cÃ³ tá»“n táº¡i khÃ´ng trÆ°á»›c khi hiá»ƒn thá»‹ Ä‘á»ƒ trÃ¡nh lá»—i
        valid_cols = [c for c in display_cols if c in high_risk_customers.columns]
        st.dataframe(high_risk_customers[valid_cols])

    with col2:
        st.subheader("ğŸ“Š Thá»‘ng kÃª giáº£i phÃ¡p")
        # Äáº¿m sá»‘ lÆ°á»£ng tá»«ng loáº¡i giáº£i phÃ¡p chÃ­nh
        # Cáº§n Ä‘áº¿m trÃªn cá»™t 'Offer_Recommendation'
        action_counts = high_risk_customers['Offer_Recommendation'].value_counts().head(5)
        st.bar_chart(action_counts)

    # 4. TÃ­nh nÄƒng GenAI (MÃ´ phá»ng soáº¡n Email)
    st.markdown("### ğŸ“§ Soáº¡n tháº£o Email tá»± Ä‘á»™ng (GenAI Simulation)")

    # Chá»n khÃ¡ch hÃ ng tá»« danh sÃ¡ch rá»§i ro
    # Sá»­a lá»—i: selectbox cáº§n má»™t list cÃ¡c giÃ¡ trá»‹ Ä‘á»ƒ chá»n
    selected_cust_id = st.selectbox("Chá»n ID khÃ¡ch hÃ ng Ä‘á»ƒ gá»­i Æ°u Ä‘Ã£i:", high_risk_customers['customerID'].tolist())

    if selected_cust_id:
        # Láº¥y thÃ´ng tin dÃ²ng dá»¯ liá»‡u cá»§a khÃ¡ch hÃ ng Ä‘Ã³
        # Sá»­a lá»—i: Láº¥y dÃ²ng dá»±a trÃªn customerID vÃ  .iloc[0] Ä‘á»ƒ cÃ³ Series
        cust_info = high_risk_customers[high_risk_customers['customerID'] == selected_cust_id].iloc[0]

        # Soáº¡n ná»™i dung email
        email_content = f"""
        ----------------------------------------------------
        **To:** {cust_info['customerID']}@softbank.ne.jp
        **Subject:** Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t dÃ nh riÃªng cho báº¡n!

        KÃ­nh gá»­i QuÃ½ khÃ¡ch,

        Cáº£m Æ¡n báº¡n Ä‘Ã£ gáº¯n bÃ³ vá»›i SoftBank suá»‘t {cust_info['tenure']} thÃ¡ng qua.
        Há»‡ thá»‘ng nháº­n tháº¥y báº¡n Ä‘ang gáº·p má»™t sá»‘ báº¥t tiá»‡n (Äiá»ƒm rá»§i ro: {cust_info['Churn_Score']:.2f}).

        ChÃºng tÃ´i xin gá»­i táº·ng báº¡n gÃ³i Æ°u Ä‘Ã£i Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng:
        ğŸ‘‰ {cust_info['Offer_Recommendation']}

        Vui lÃ²ng má»Ÿ á»©ng dá»¥ng PayPay Ä‘á»ƒ nháº­n ngay.
        ----------------------------------------------------
        """
        st.code(email_content, language='text')

        if st.button("ğŸš€ Gá»­i Email Giá»¯ ChÃ¢n"):
            st.success(f"ÄÃ£ gá»­i Æ°u Ä‘Ã£i thÃ nh cÃ´ng tá»›i khÃ¡ch hÃ ng {selected_cust_id}!")
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
import pickle

# --- 1. Táº£i vÃ  LÃ m sáº¡ch Dá»¯ liá»‡u ---
def load_and_clean_data(file_path):
    df = pd.read_csv(file_path)
    
    # Xá»­ lÃ½ TotalCharges
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    df.dropna(subset=['TotalCharges'], inplace=True)
    
    # MÃ£ hÃ³a biáº¿n má»¥c tiÃªu Churn
    le = LabelEncoder()
    df['Churn'] = le.fit_transform(df['Churn']) # Yes=1, No=0
    
    # Loáº¡i bá» customerID vÃ  gender 
    df.drop(['customerID', 'gender'], axis=1, inplace=True) 
    
    return df

# --- 2. Äá»‹nh nghÄ©a Quy trÃ¬nh Tiá»n xá»­ lÃ½ (Preprocessor) ---
def create_preprocessor(df):
    categorical_cols = [col for col in df.columns if df[col].dtype == 'object']
    numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']
    
    numerical_transformer = Pipeline(steps=[
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numerical_transformer, numerical_cols),
            ('cat', categorical_transformer, categorical_cols)
        ],
        remainder='drop'
    )
    return preprocessor, categorical_cols, numerical_cols

# --- 3. Huáº¥n luyá»‡n MÃ´ hÃ¬nh Cuá»‘i cÃ¹ng (Pipeline) ---
def train_full_pipeline(df):
    X = df.drop('Churn', axis=1)
    y = df['Churn']
    
    preprocessor, categorical_cols, numerical_cols = create_preprocessor(X)
    
    # XÃ¢y dá»±ng Pipeline hoÃ n chá»‰nh
    full_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42, class_weight='balanced'))
    ])
    
    full_pipeline.fit(X, y)
    
    return full_pipeline, categorical_cols, numerical_cols, X.columns.tolist()

# --- Thá»±c thi vÃ  LÆ°u trá»¯ ---
if __name__ == '__main__':
    # ÄÆ¯á»œNG DáºªN Cá» Äá»ŠNH CHO Má»¤C ÄÃCH HUáº¤N LUYá»†N
    file_path = 'WA_Fn-UseC_-Telco-Customer-Churn.csv' 
    
    df_clean = load_and_clean_data(file_path)
    
    pipeline_model, categorical_cols, numerical_cols, original_features = train_full_pipeline(df_clean)
    
    # LÆ°u Pipeline vÃ  cÃ¡c biáº¿n cáº§n thiáº¿t
    with open('full_churn_pipeline.pkl', 'wb') as file:
        pickle.dump({
            'pipeline': pipeline_model,
            'categorical_cols': categorical_cols,
            'numerical_cols': numerical_cols,
            'original_features': original_features
        }, file)
    
    print("\n[THÃ€NH CÃ”NG] ÄÃ£ lÆ°u mÃ´ hÃ¬nh Pipeline hoÃ n chá»‰nh vÃ o 'full_churn_pipeline.pkl'.")
